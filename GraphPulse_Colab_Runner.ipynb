{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphPulse Benchmark Runner - Google Colab\n",
    "\n",
    "This notebook runs GraphPulse benchmarks on Google Colab with CUDA GPU support.\n",
    "\n",
    "**Target Dataset:** `dgd`\n",
    "\n",
    "**Models to Run:**\n",
    "- HTGN (Hyperbolic Temporal Graph Network)\n",
    "- EvolveGCN\n",
    "- GRUGCN\n",
    "- GraphPulse (RNN)\n",
    "- GIN (Static Baseline - Raw Graphs)\n",
    "- TDA-GIN (Static Baseline - TDA Graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Optional - for saving results)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# RESULTS_PATH = '/content/drive/MyDrive/GraphPulse_Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/trangiahuy8444/GraphPulse.git\n",
    "\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PyTorch and CUDA version\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric and dependencies\n",
    "import torch\n",
    "torch_version = torch.__version__.split('+')[0]  # Remove +cu118 suffix if present\n",
    "\n",
    "!pip install torch-geometric\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-{torch_version}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install other dependencies\n",
    "!pip install kmapper geoopt networkx scikit-learn pandas numpy matplotlib tqdm pyyaml tensorflow\n",
    "\n",
    "print(\"\u2713 All dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset exists\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "if not os.path.exists('data/all_network/networkdgd.txt'):\n",
    "    print(\"WARNING: networkdgd.txt not found!\")\n",
    "    print(\"Please upload the file to data/all_network/networkdgd.txt\")\n",
    "else:\n",
    "    print(\"\u2713 Dataset file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data preprocessing\n",
    "import sys\n",
    "sys.path.insert(0, '/content/GraphPulse')\n",
    "\n",
    "from analyzer.network_parser import NetworkParser\n",
    "\n",
    "parser = NetworkParser()\n",
    "parser.file_path = \"./data/all_network/\"\n",
    "parser.timeseries_file_path = \"./data/all_network/TimeSeries/\"\n",
    "\n",
    "network_name = \"networkdgd.txt\"\n",
    "\n",
    "print(\"Starting data preprocessing...\")\n",
    "parser.create_graph_features(network_name)\n",
    "parser.create_time_series_graphs(network_name)\n",
    "print(\"\u2713 Data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: HTGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HTGN\n",
    "import os\n",
    "os.chdir('/content/GraphPulse/models/temporal_gnn/script')\n",
    "\n",
    "!python main.py --dataset dgd --model HTGN --device cuda --device_id 0 --seed 1024 --max_epoch 500 --patience 50 --lr 0.01 --nfeat 128 --nhid 16 --nout 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: EvolveGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EvolveGCN\n",
    "import os\n",
    "os.chdir('/content/GraphPulse/models/temporal_gnn/script')\n",
    "\n",
    "!python main.py --dataset dgd --model EvolveGCN --egcn_type EGCNH --device cuda --device_id 0 --seed 1024 --max_epoch 500 --patience 50 --lr 0.01 --nfeat 128 --nhid 16 --nout 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRUGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GRUGCN\n",
    "import os\n",
    "os.chdir('/content/GraphPulse/models/temporal_gnn/script')\n",
    "\n",
    "!python main.py --dataset dgd --model GRUGCN --device cuda --device_id 0 --seed 1024 --max_epoch 500 --patience 50 --lr 0.01 --nfeat 128 --nhid 16 --nout 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: GraphPulse (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GraphPulse RNN\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "!python models/rnn/rnn_methods.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: GIN (Static Baseline - Raw Graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/static_gnn/config_GIN.yml\n",
    "hidden_units:\n  - [64, 64, 64, 64]\ndropout:\n  - 0.5\ntrain_eps:\n  - true\naggregation:\n  - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('models/static_gnn/GnnResults', exist_ok=True)\n",
    "os.makedirs('GnnResults', exist_ok=True)\n",
    "print(\"\u2713 Output directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify static_graph_methods.py to run only for dgd dataset\n",
    "# Create a backup and modify the networkList\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "# Backup original file\n",
    "!cp models/static_gnn/static_graph_methods.py models/static_gnn/static_graph_methods.py.backup\n",
    "\n",
    "# Modify to run only dgd dataset\n",
    "import re\n",
    "with open('models/static_gnn/static_graph_methods.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Replace networkList with dgd only\n",
    "content = re.sub(\n",
    "    r'networkList = \\[.*?\\]',\n",
    "    'networkList = [\"networkdgd.txt\"]',\n",
    "    content,\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "\n",
    "# Update TDA variable to match actual folder (Overlap_0.3_Ncube_2)\n",
    "content = re.sub(\n",
    "    r'read_torch_time_series_data\\(network, \"Overlap_xx_Ncube_x\"\\)',\n",
    "    'read_torch_time_series_data(network, \"Overlap_0.3_Ncube_2\")',\n",
    "    content\n",
    ")\n",
    "\n",
    "with open('models/static_gnn/static_graph_methods.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"\u2713 Modified static_graph_methods.py for dgd dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GIN (Raw) - using TemporalVectorizedGraph_Tuned data\n",
    "# First, create a helper function version for raw graphs\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "# Modify script to use raw graphs for GIN\n",
    "import re\n",
    "with open('models/static_gnn/static_graph_methods.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Add helper function before main block\n",
    "helper_func = '''\n",
    "def read_torch_time_series_data_raw(network):\n",
    "    \"\"\"Read raw graph data (without TDA features) for GIN baseline\"\"\"\n",
    "    file_path_temporal = \"PygGraphs/TimeSeries/{}/TemporalVectorizedGraph_Tuned/\".format(network)\n",
    "    GraphDataList = []\n",
    "    import os\n",
    "    import pickle\n",
    "    \n",
    "    if os.path.exists(file_path_temporal):\n",
    "        files = sorted([f for f in os.listdir(file_path_temporal) if f.endswith(('.txt', '.pkl'))])\n",
    "        for file in files:\n",
    "            with open(file_path_temporal + file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                GraphDataList.append(data)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"TemporalVectorizedGraph_Tuned not found for {network}\")\n",
    "    return GraphDataList\n",
    "\n",
    "'''\n",
    "\n",
    "# Insert helper function\n",
    "content = content.replace('if __name__ == \"__main__\":', helper_func + '\\nif __name__ == \"__main__\":')\n",
    "\n",
    "# Change to use raw data function\n",
    "content = re.sub(\n",
    "    r'data = read_torch_time_series_data\\(network, \"Overlap_0\\.3_Ncube_2\"\\)',\n",
    "    'data = read_torch_time_series_data_raw(network)',\n",
    "    content\n",
    ")\n",
    "\n",
    "with open('models/static_gnn/static_graph_methods.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Run GIN (Raw)\n",
    "!cd /content/GraphPulse && python models/static_gnn/static_graph_methods.py\n",
    "\n",
    "print(\"\u2713 GIN (Raw) training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: TDA-GIN (Static Baseline - TDA Graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore original and modify for TDA-GIN\n",
    "import os\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "# Restore from backup\n",
    "!cp models/static_gnn/static_graph_methods.py.backup models/static_gnn/static_graph_methods.py\n",
    "\n",
    "# Modify for TDA-GIN (dgd only, correct TDA folder)\n",
    "import re\n",
    "with open('models/static_gnn/static_graph_methods.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Replace networkList\n",
    "content = re.sub(\n",
    "    r'networkList = \\[.*?\\]',\n",
    "    'networkList = [\"networkdgd.txt\"]',\n",
    "    content,\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "\n",
    "# Update TDA variable\n",
    "content = re.sub(\n",
    "    r'read_torch_time_series_data\\(network, \"Overlap_xx_Ncube_x\"\\)',\n",
    "    'read_torch_time_series_data(network, \"Overlap_0.3_Ncube_2\")',\n",
    "    content\n",
    ")\n",
    "\n",
    "with open('models/static_gnn/static_graph_methods.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Run TDA-GIN\n",
    "!cd /content/GraphPulse && python models/static_gnn/static_graph_methods.py\n",
    "\n",
    "print(\"\u2713 TDA-GIN training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Result Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir('/content/GraphPulse')\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_filename = f'GraphPulse_dgd_results_{timestamp}.zip'\n",
    "\n",
    "dirs_to_zip = [\n",
    "    'models/temporal_gnn/saved_models',\n",
    "    'models/temporal_gnn/data/output',\n",
    "    'models/rnn/RnnResults',\n",
    "    'models/static_gnn/GnnResults',\n",
    "    'GnnResults'\n",
    "]\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for dir_path in dirs_to_zip:\n",
    "        if os.path.exists(dir_path):\n",
    "            for root, dirs, files in os.walk(dir_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, '/content/GraphPulse')\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"\u2713 Zip file created: {zip_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "files.download(zip_filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}